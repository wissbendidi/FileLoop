# ================================
# PROJECT CONTEXT
# ================================
- We are building a **local AI-powered file cleaner**.
- Goal: Help users clean up their computer by scanning files, classifying them with AI, and showing results in an interactive UI.
- All processing must run locally. âŒ No cloud APIs. âŒ Never upload user files to the internet.
- The tool should be **safe, private, modular, and easy to share**.

# ================================
# CORE FEATURES
# ================================
- Scan directories to collect file metadata:
  - path, name, extension, size, last accessed/modified time
- Generate embeddings using a local model (e.g. SentenceTransformers `all-MiniLM-L6-v2`).
- Cluster or classify files into categories:
  - By type (images, videos, docs, code, audio, etc.)
  - By usage (large, old, rarely accessed, duplicates)
- Interactive visualization:
  - Show file clusters with treemaps / sunburst charts
  - Allow filters (by size, type, cluster)
- Interactive UI with **Streamlit**:
  - Directory selection
  - File cluster display
  - Suggested cleanup actions
- Safety:
  - Never delete files directly
  - Instead, move files to a "quarantine" folder where user can review later

# ================================
# NICE-TO-HAVE FEATURES
# ================================
- Detect duplicate files via hashing (SHA256/MD5).
- AI-generated labels for clusters (optional local LLM).
- Gamification (e.g., â€œYou freed 2GB ğŸ‰â€).
- Export results as CSV/JSON.
- Simple search bar to locate files quickly.

# ================================
# TECH STACK
# ================================
- Python 3.10+
- Libraries:
  - `os`, `time`, `hashlib` â†’ file scanning + duplicates
  - `sentence-transformers` â†’ embeddings
  - `scikit-learn` â†’ clustering (KMeans, DBSCAN)
  - `pandas` â†’ data handling
  - `plotly` â†’ visualization (treemap, sunburst)
  - `streamlit` â†’ interactive UI
  - `PyPDF2`, `python-docx` â†’ extract content from PDFs/Docs
- Testing: `pytest`

# ================================
# ARCHITECTURE
# ================================
FileLoop
â”‚â”€â”€ README.md               # Instructions
â”‚â”€â”€ requirements.txt        # Dependencies
â”‚â”€â”€ cursor.rules            # This file
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ scanner.py          # File scanning
â”‚   â”œâ”€â”€ embeddings.py       # Embedding generation
â”‚   â”œâ”€â”€ classifier.py       # File clustering/classification
â”‚   â”œâ”€â”€ visualization.py    # Treemap/sunburst charts
â”‚   â”œâ”€â”€ ui.py               # Streamlit app
â”‚   â””â”€â”€ utils.py            # Helpers (hashing, file ops)
â”‚â”€â”€ data/                   # Example/test files
â”‚â”€â”€ models/                 # Local ML models (if downloaded)
â””â”€â”€ tests/                  # Unit tests

# ================================
# DEVELOPMENT RULES
# ================================
- Always use type hints and docstrings.
- Keep modules small and modular.
- When writing code, also generate example usage.
- Avoid hardcoding paths â†’ always let user select a directory.
- Ensure safety: files are only moved to quarantine, not deleted.
- Write pytest tests for each core module.
- Use Plotly for charts; never matplotlib for Streamlit integration.
- Prioritize performance â†’ scanning and clustering should handle thousands of files.
